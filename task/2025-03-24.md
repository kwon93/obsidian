##### #TODO 
- [ ] 전주검증웹 ( Main )
	- [x] insert 시에 distance값 구해서 3m 이내일 경우 envType 2로 저장하는 로직 추가 
		- 최종 테이블 생성시 로직 추가로 수정됨 
	- [ ] 중간테이블 생성 API 
		- [x] exceljs libary install 
		- [ ] flask 요청 
		- [ ] 엑셀 파싱 후 테이블 생성한 뒤 값 넣기 
	- [x] query 수정에 따른 Sequelize code 수정 진행 
	- [ ] Insert Logic reafactoring 
	- [ ] Transaction , lock  동시성 처리 
		- **NOWAIT**: 잠금을 즉시 획득할 수 없는 경우 기다리지 않고 바로 오류를 발생
	- [ ] pagination 처리  
- [ ] ITX Csv, Xlsx 다운로드 API 
	-  최우선 순위 ( 03/28 까지 마무리 )
		- [ ]  1 전차선 높이 / 편위 첨극 
		- [ ] 21 궤도선형 분야 - 파이버 프로 
- [x] 4호선 xslx 수정본 배포하기 ( 월요일 진행해야함 )
		


---

###### 전주 검증 회의록
	1. pds , tsi 링크 알고리즘 개선 
		1. 같은 전주 번호인데 타코 미터가 50m 이상 차이나는 경우가 있다. 
	2. 최종 테이블 생성시 중첩이면 중첩인 모든 브라켓이 최종 테이블로 생성되도록  
	3. tsi 방향 상행 하행 반대 방향이란것을 화면에서 보여줄 수 있도록 
			- 서정선 상행 , 동정선 하행 
		1. 상선일때는 좌측을 보고 하선일때는 우측만 강조하는 형식 
		2. 노선 방향에 따라 이미지 강조를 해야하는 기준 및 케이스를 세워야 한다. 
		3. tra 는 pds 이미지가 혼란을 주기때문에 검증자가 tsi, pds 보고싶은 이미지만 선택해 보는것은 어떨까 -> 대표님 승인이 필요함 ( 소장님 의견 )
			1. 대표님이 반대하실 경우 tsi 좌측 이미지만 강조해주는걸로 
		( tra는 전주 번호가 브라켓에 있기때문에 브라켓을 찍을 수 있는 tsi 가 필요 )
	4. Track 정보를 박재열과장님이 직접 넣어주기로 함  Backend 에서는 중간 테이블의 Track 값을 가져오면 된다 
	5. envType 은 중간테이블에서 없애고 최종 생성 테이블에서 만들어주는걸로 
		1. 검수자는 브라켓 클릭만 하도록 
	6. 3m 이하는 중첩으로 간다 
	7. expend -> bracket 다 펼쳐서 보여주기 
	8. 계정을 추가해 계정별로 검증을 진행하기 
	9. 최종 생성 테이블 화면에 id 말고 imageIndex 넣기 
	10. 중간 테이블 생성하는 API 생성하기 플라스크로 요청 
		1. 비동기 처리가 안되있어서 비동기 처리가 필요함 
			1. 비동기 결과를 어떻게 확인할건지 -> 중간 테이블 생성이 완료 됬는지 
			2. [input tag] 생성, 오픈 



###### 중간 테이블 생성 스크립트 

```
import pandas as pd
import psycopg2
import ast
from datetime import datetime

excel_file_path = "20250107_tra.xlsx"
df = pd.read_excel(excel_file_path, engine="openpyxl")

def parsing_timestamp(timestamp_str):
    """ YYYYMMDDHHMMSS.%f 형식의 문자열을 PostgreSQL TIMESTAMP로 변환 """
    dt_object = datetime.strptime(timestamp_str, "%Y%m%d%H%M%S.%f")
    return dt_object.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]

# 쿼리문 반환 함수
def select_ocr_query(cur, schema, table, bracket_tacho, scope=15, resolution=0.659611739):
    query = f"""
        SELECT device, direction,
            CASE WHEN diff <= {scope} THEN pole_number ELSE NULL END AS pole_number,
            CASE WHEN diff <= {scope} THEN org_name ELSE NULL END AS org_name,
            CASE WHEN diff <= {scope} THEN crop_name ELSE NULL END AS crop_name 
        FROM (
            SELECT 
                device,
                direction,
                pole_number,
                org_name,
                crop_name,
                ABS({bracket_tacho} - tacho) * {resolution} / 1000 AS diff,
                ROW_NUMBER() OVER (
                    PARTITION BY device, direction 
                    ORDER BY ABS({bracket_tacho} - tacho) ASC
                ) AS rn
            FROM {schema}.{table}
            WHERE (device = 'PDS' AND direction IN ('L', 'R'))
            OR (device = 'TSI' AND direction IN ('L', 'R'))
        ) sub_query
        WHERE rn = 1;
    """
    cur.execute(query)
    results = cur.fetchall()

    # 딕셔너리 변환
    data_dict = {
        (row[0], row[1]): (row[2], row[3], row[4])
        for row in results
    }

    return data_dict

schema = "tra"
conn = psycopg2.connect(
    host="192.168.10.2",
    port="5432",
    dbname="LDS_V2",
    user="iisys",
    password="2isys"
)

cur = conn.cursor()

cur.execute(f"DROP TABLE IF EXISTS {schema}.t_pole_image;")
cur.execute(f"""
CREATE TABLE {schema}.t_pole_image (
    id SERIAL PRIMARY KEY,
    track VARCHAR(255),
    track_unit VARCHAR(255),
    date TIMESTAMP,
    image_index INT,
    bracket_count INT,
    lsi_image_path TEXT,
    lsi_lon FLOAT,
    lsi_lat FLOAT,
    image_tacho FLOAT
);""")
cur.execute(f"CREATE INDEX image_index_i ON {schema}.t_pole_image (image_index);")

cur.execute(f"DROP TABLE IF EXISTS {schema}.t_pole_bracket")
cur.execute(f"""
CREATE TABLE {schema}.t_pole_bracket (
    id SERIAL PRIMARY KEY,
    image_index INT,
    pole_x FLOAT,
    pole_y FLOAT,
    pixel_count FLOAT,
    kp FLOAT,
    bracket_tacho FLOAT,
    distance FLOAT,
    pole_number TEXT,
    env_type INT,
    pds_lon FLOAT,
    pds_lat FLOAT,
    tsi_lon FLOAT,
    tsi_lat FLOAT,
    pds_ocr_r_crop TEXT,
    pds_ocr_l_crop TEXT,
    pds_ocr_r_org TEXT,
    pds_ocr_l_org TEXT,
    tsi_ocr_r_crop TEXT,
    tsi_ocr_l_crop TEXT,
    tsi_ocr_r_org TEXT,
    tsi_ocr_l_org TEXT,
    pds_num_r TEXT,
    pds_num_l TEXT,
    tsi_num_r TEXT,
    tsi_num_l TEXT
);""")

conn.commit()

image_data = []
bracket_data = []

prev_pixel_count = 0
image_path_prefix = "/mnt/nas-data/ldb_home"
is_prev_bracket = False

for idx, row in df.iterrows():
    pole_index = int(row["pole_index"]) if not pd.isna(row["pole_index"]) else None
    image_index = int(row["image_index"])
    lsi_lon = float(row["lsi_lon"]) if not pd.isna(row["lsi_lon"]) else None
    lsi_lat = float(row["lsi_lat"]) if not pd.isna(row["lsi_lat"]) else None
    labels = sorted(ast.literal_eval(row["Labels"]), key=lambda x: x[2]) if not pd.isna(row["Labels"]) else []
    bracket_count = len(labels)
    if bracket_count == 0:
        is_prev_bracket = False

    # LSI 이미지 경로 및 DATE
    if not pd.isna(row["LSI_name"]):
        lsi_name = row["LSI_name"]
        try:
            date, time, _, _, _, _, image_tacho, _ = lsi_name.split("_")
            image_tacho = float(image_tacho)
            lsi_image_path = f"{image_path_prefix}/{date}_tra/LSI/{date}/{date}{time[:3]}0/{lsi_name}"
            timestamp = parsing_timestamp(date + time)
        except:
            print(f"LSI 이미지 데이터 오류: {lsi_name}")
            break
    else:
        timestamp, image_tacho, lsi_image_path = None, None, None

    image_data.append((
        "종관선 북단-동정선", "종관선 북단-동정선(쌍선)-난강-신주", timestamp, image_index, bracket_count,
        lsi_image_path, lsi_lon, lsi_lat, image_tacho
    ))

    pds_lon = float(row["pds_lon"]) if not pd.isna(row["pds_lon"]) else None
    pds_lat = float(row["pds_lat"]) if not pd.isna(row["pds_lat"]) else None
    tsi_lon = float(row["tsi_lon"]) if not pd.isna(row["tsi_lon"]) else None
    tsi_lat = float(row["tsi_lat"]) if not pd.isna(row["tsi_lat"]) else None

    # 전 이미지 끝 타코
    prev_image_tacho = float(df.loc[df["image_index"] == (image_index - 1), "tacho"].values[0]) if image_index != 0 else 0
    
    for _, y, x, _, _, _ in labels:
        pole_x, pole_y = float(x), float(y)
        pixel_count = image_index * 4000 + pole_x
        kp = pixel_count / 1000
        distance = (pixel_count - prev_pixel_count) / 1000 if pole_index != 100 else 0
        prev_pixel_count = pixel_count
        # 브라켓 타코 = ((현재 이미지 타코 - 전 이미지 타코) / 4000 * poleX 절대값) + 전 이미지 타코
        bracket_tacho = ((image_tacho - prev_image_tacho) / 4000 * pole_x) + prev_image_tacho
        # OCR 관련 이미지 조회 쿼리 실행
        ocr_dict = select_ocr_query(cur, schema, "t_pole_ocr", bracket_tacho)
        pds_num_r, pds_ocr_r_org_path, pds_ocr_r_crop_path = ocr_dict[("PDS", "R")]
        pds_num_l, pds_ocr_l_org_path, pds_ocr_l_crop_path = ocr_dict[("PDS", "L")]
        tsi_num_r, tsi_ocr_r_org_path, tsi_ocr_r_crop_path = ocr_dict[("TSI", "R")]
        tsi_num_l, tsi_ocr_l_org_path, tsi_ocr_l_crop_path = ocr_dict[("TSI", "L")]

        # 이웃한 브라켓이 있는 경우
        if is_prev_bracket:
            bracket_data[-1][8]= 1
            env_type = 1
        else:
            env_type = 0

        bracket_data.append([
            image_index, pole_x / 4000, pole_y / 2028,
            pixel_count, kp, bracket_tacho, distance,
            tsi_num_l, env_type, pds_lon, pds_lat, tsi_lon, tsi_lat,
            pds_ocr_r_crop_path, pds_ocr_l_crop_path, pds_ocr_r_org_path, pds_ocr_l_org_path,
            tsi_ocr_r_crop_path, tsi_ocr_l_crop_path, tsi_ocr_r_org_path, tsi_ocr_l_org_path,
            pds_num_r, pds_num_l, tsi_num_r, tsi_num_l
        ])

        is_prev_bracket = True

bracket_data = [tuple(item) for item in bracket_data]

cur.executemany(
    f"""
    INSERT INTO {schema}.t_pole_image (
        track, track_unit, date, image_index, bracket_count,
        lsi_image_path, lsi_lon, lsi_lat, image_tacho
    )
    VALUES (
        %s, %s, %s, %s, %s,
        %s, %s, %s, %s
    );
    """, image_data
)

cur.executemany(
    f"""
    INSERT INTO {schema}.t_pole_bracket (
        image_index, pole_x, pole_y,
        pixel_count, kp, bracket_tacho, distance,
        pole_number, env_type, pds_lon, pds_lat, tsi_lon, tsi_lat,
        pds_ocr_r_crop, pds_ocr_l_crop, pds_ocr_r_org, pds_ocr_l_org,
        tsi_ocr_r_crop, tsi_ocr_l_crop, tsi_ocr_r_org, tsi_ocr_l_org,
        pds_num_r, pds_num_l, tsi_num_r, tsi_num_l
    )
    VALUES (
        %s, %s, %s,
        %s, %s, %s, %s,
        %s, %s, %s, %s, %s, %s,
        %s, %s, %s, %s,
        %s, %s, %s, %s,
        %s, %s, %s, %s
    );
    """, bracket_data
)

conn.commit()
cur.close()
conn.close()
```


POST http://192.168.0.51:5000/generate_xlsx_file?target_dir=
```
@app.route(
  '/generate_xlsx_file', methods = [ 'POST' ]
) def generate_xlsx_file(): try : logger.info(
  "=== generate_xlsx_file API 호출 시작 ==="
) data = request.get_json() logger.info(f "입력 데이터: {data}") target_dir = data.get("target_dir") logger.info(
  f "처리할 폴더: {target_dir}"
) script_path = os.path.join(
  os.path.dirname(
    os.path.abspath(__file__)
  ), 
  "iisys/ldb/00_run_all.py"
) logger.info(
  f "실행할 스크립트: {script_path}"
) if not os.path.exists(script_path): error_msg = f "스크립트를 찾을 수 없음: {script_path}" logger.error(error_msg) return jsonify(
  { "status" : "error", "message" : error_msg}
), 
500 logger.info("스크립트 실행 시작") result = subprocess.run(
  [ "python3", 
  script_path, 
  "--folder", 
  target_dir], 
  capture_output = True, 
  text = True, 
  cwd = os.path.dirname(
    os.path.abspath(__file__)
  )
) # 출력 정리
stdout_clean = clean_ansi(result.stdout) stderr_clean = clean_ansi(result.stderr) # 출력을 줄 단위로 로깅
for line in stdout_clean.split('\n'): if line.strip(): logger.info(
  f "스크립트 출력: {line.strip()}"
) for line in stderr_clean.split('\n'): if line.strip(): logger.error(
  f "스크립트 에러: {line.strip()}"
) if result.returncode == 0 : logger.info(
  "=== 스크립트 실행 성공 ==="
) return jsonify({ "status" : "success" }), 
200 else : logger.error(
  f "=== 스크립트 실행 실패 (리턴 코드: {result.returncode}) ==="
) return jsonify(
  { "status" : "error", "message" : "스크립트 실행 실패", 
  "stdout" : stdout_clean, "stderr" : stderr_clean, 
  "returncode" : result.returncode }
), 
500 
except 
  Exception as e : logger.exception("=== 예외 발생 ===") return jsonify(
    { "status" : "error", 
    "message" : str(e), 
    "type" : type(e).__name__ }
  ), 
  500

```